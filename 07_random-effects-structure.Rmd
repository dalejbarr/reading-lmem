# Random effects structure

## Resources

[Slides](slides/07_simgen/index.html)

[Crossed web app](https://shiny.psy.gla.ac.uk/Dale/crossed) demonstrating random effects for a simple crossed design

## Maximal random effects

:::{.try}

For this first part, you will load in datasets created for you. Your task is to inspect the data and then to write the formula corresponding to the 'maximal' random effects structure.

Download the following files and place them in your working directory.

- [`fdata1.rds`](data/fdata1.rds)
- [`fdata2.rds`](data/fdata2.rds)
- [`fdata3.rds`](data/fdata3.rds)
- [`fdata4.rds`](data/fdata4.rds)

Then load them in using

```{r load-in, eval=FALSE}
library("tidyverse")

fdata1 <- readRDS("fdata1.rds")
fdata2 <- readRDS("fdata2.rds")
fdata3 <- readRDS("fdata3.rds")
fdata4 <- readRDS("fdata4.rds")
```

```{r load-in-hidden, include=FALSE}
fdata1 <- readRDS("data/fdata1.rds")
fdata2 <- readRDS("data/fdata2.rds")
fdata3 <- readRDS("data/fdata3.rds")
fdata4 <- readRDS("data/fdata4.rds")
```

The dataset `fdata1` is from a factorial experiment with design factors `C`, `E`, and `W` and dependent variable `rtime`. Individual subjects are identified by the variable `subject_id`.

Type the `lme4::lmer()` model formula you would use to analyze these data with maximal random effects (just the formula, e.g., `Y ~ Z + (Z | id)`, not the full `lmer()` call).

**You do not need to create numeric predictors to use in the formula. Just use `C`, `E`, and `W` as they are.**

```{r task-1, webex.hide="solution", eval=FALSE}
rtime ~ C * E * W + (C * E * W | subject_id)
```

The dataset `fdata2` is from a factorial experiment with design factors `J`, `T`, and `W` and dependent variable `depvar`. Individual subjects are identified by the variable `subject_id`.

Type the `lme4::lmer()` model formula you would use to analyze these data with maximal random effects.

```{r task-2, webex.hide="solution", eval=FALSE}
depvar ~ J * T * W + (W | subject_id)
```

The dataset `fdata3` is from a factorial experiment with independent variables `B`, `P`, and `U` and dependent variable `rtime`. The design includes crossed random factors of subjects and stimuli, with subjects identified by variable `subject_id`, and stimuli by variable `stim_id`.

Type the `lme4::lmer()` model formula you would use to analyze these data with maximal random effects.

```{r task-3, webex.hide="solution", eval=FALSE}
rtime ~ B * P * U + (B * U | subject_id) + (P | stim_id)
```

The dataset `fdata4` is from a factorial experiment with independent variables `G`, `L`, and `T` and dependent variable `rtime`. The design includes crossed random factors of subjects and stimuli, with subjects identified by variable `sub_id`, and stimuli by variable `stm_id`.

Type the `lme4::lmer()` model formula you would use to analyze these data with maximal random effects.

```{r task-4, webex.hide="solution", eval=FALSE}
rtime ~ G * L * T + (1 | sub_id) + (L | stm_id)
```
:::

## Re-analysis of Keysar, Barr, Balin & Brauner, Experiment 2

For this task, you will be re-analyzing data from **Experiment 2** of this paper:

Keysar, B., Barr, D. J., Balin, J. A. & Brauner, J. S. (2000). [Taking Perspective In Conversation: The Role of Mutual Knowledge In Comprehension](https://journals.sagepub.com/doi/abs/10.1111/1467-9280.00211). *Psychological Science*, 11, 32--38.

![view of basic experimental task](images/KBBB2000Setup.png)

This experiment examined perspective taking during conversation. In the experiment, participants ("addressees") sat across from a confederate director who instructed them to move objects around in a grid placed between them while their eyes were tracked. For example, the director might say, "move the truck one space down." The grid contained some objects hidden from the director's view. The experiment was structured such that the director would occasionally refer to a mutually visible object ("move the small candle...") in a way that would also happen to describe a "competitor" object that was visible only to the addressee. Because this object was hidden the addressee had little reason to think the director would know of its identity.

For instance, consider that in the above figure the director sees two candles, a large and a small one, while the participant (addressee) sees three candlesâ€”the two that the director sees, plus a third one that is hidden, and even smaller than the director's "small" candle. To the extent that addressee's have difficulty taking the speaker's perspective, they should be confused by this additional candle that is privileged to them.

In addition to this main condition (indicated in the data by the `cond` variable having the value `E`), there was also a control condition where the hidden competitor (the addressee's smallest candle) was replaced with an object that would not match the description (indicated by `cond` being `C`).

The experiment previous to the one that you will re-analyse established that these hidden competitor produced "egocentric interference" that delayed interpretation.

In the current experiment (Experiment 2), the question was whether the "source" of these hidden objects mattered. In one condition (`psource = EX`) the experimenter gave the participants the objects to hide. In another condition (`psource = RN`), participants drew numbers from a bag, believing that this random lottery determined which objects went in the hidden spaces.

Thus, the experiment was a 2 (source, EX or RN) by 2 (condition, E or C) design. The experiment had crossed random factors of subject (`subj`) and stimulus (`object`), but was analyzed using separate by-subjects and by-items analysis. Your task is to re-analyze the analyses of the DVs `firstfix` and `rt` using linear mixed-effects model with appropriately specified random effects for subjects ('subj') and stimuli (`object`).

Make a new working directory, download the R binary (`.rds`) file [kbbb_2000.rds](data/kbbb_2000.rds), and place it in the directory. Start and new R script (or RMarkdown script) and save it in the working directory along with the data.

At the top of your script, type the following lines to set up your session (you might want to restart R before doing this):

```{r startup, eval=FALSE}
library("lme4")
library("tidyverse")

kbbb <- readRDS("kbbb_2000.rds")
```

```{r startup-hidden, include=FALSE}
library("lme4")
library("tidyverse")

kbbb <- readRDS("data/kbbb_2000.rds")
```

Have a look at the tibble `kbbb`. A description of the fields is below.

| Variable | Description |
|:---------|:------------| 
| `subj`  | unique integer identifying each subject |
| `psource` | source of hidden objects (`EX` = experimenter, `RN` = random)   |
| `object`   | experimental stimulus identifier                                              |
| `cond`     | whether critical hidden object was competitor (`E`) or noncompetitor (`C`)    |
| `firstfix` | first fixation on the target (in milliseconds)                                |
| `rt`       | final fixation on the target (in milliseconds)                                |
| `regrab`   | reaches/grabs of critical hidden object (`R` = reach, `G` = grab, `-` = none) |
| `nfix`     | number of fixations on the critical hidden object                             |
| `totfix`   | total fixation time on critical hidden object (in milliseconds)               |

The DVs you should analyze is `firstfix`. 

From this point on, you're on your own. Don't peek at the solution until you have given it your best shot. Good luck!

`r hide("solution")`

```{r solution}
## make deviation-coded predictors
kbbb2 <- kbbb %>%
  mutate(C = if_else(cond == "E", .5, -.5),
         PS = if_else(psource == "EX", .5, -.5))

## double check
kbbb2 %>%
  count(cond, psource, C, PS)
```

**First fixation analysis**

```{r ffix1}
## just get some descriptive stats
ff_means <- kbbb2 %>%
  group_by(psource, cond) %>%
  summarise(m = mean(firstfix, na.rm = TRUE), 
            sd = sd(firstfix, na.rm = TRUE),
            .groups = "drop")

ff_means
```

(*Note*: it's a good idea to plot the data before analysis as well, so we'll make a factorial plot)

```{r solution2}
ggplot(ff_means, aes(cond, m, colour = psource)) +
  geom_point(aes(shape = psource), size = 4) +
  geom_line(aes(group = psource))
```

Check out the random effects structure, by subject.

```{r firstfix-bysub}
kbbb2 %>%
  count(subj, psource, cond)
```

Need a by-subject random slope for `cond`.

Check out the random effects structure, by stimulus.

```{r firstfix-byitem}
kbbb2 %>%
  count(object, psource, cond)
```

Need by-stimulus random slopes for `psource`, `cond`, and their interaction.

Now we're ready to fit the model

```{r firstfix-lmem}
ff_mod <- lmer(firstfix ~ PS * C + (C | subj) + (PS * C | object), kbbb2,
               REML = FALSE) # for model comparison

## we get boundary (singular) fit: see ?isSingular
## look at the results and see if we should simplify
summary(ff_mod) %>% print(corr = FALSE)
```

```{r firstfix-lmem2}
ff_mod2 <- lmer(firstfix ~ PS * C + (C || subj) + (PS * C || object), kbbb2,
               REML = FALSE) # for model comparison

## still, boundary (singular) fit: see ?isSingular
## look at the results and see if we should simplify
summary(ff_mod2) %>% print(corr = FALSE)
```

```{r firstfix-lmem3}
ff_mod3 <- lmer(firstfix ~ PS * C + (C || subj) + (PS + C || object), kbbb2,
               REML = FALSE) # for model comparison

summary(ff_mod3) %>% print(corr = FALSE)
```

```{r firstfix-modelcomparison}
ff_mod_PS <- update(ff_mod3, . ~ . -PS)
ff_mod_C <- update(ff_mod3, . ~ . -C)
ff_mod_PSC <- update(ff_mod3, . ~ . -PS:C)

## test of main effect of PS
anova(ff_mod_PS, ff_mod3)

## test of main effect of C
anova(ff_mod_C, ff_mod3)

## test of PS:C interaction
anova(ff_mod_PSC, ff_mod3)
```
